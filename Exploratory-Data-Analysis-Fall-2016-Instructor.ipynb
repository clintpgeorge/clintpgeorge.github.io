{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "The goal of today's discussion is to give some insights about exploring high dimensional datasets. We will look into two popular methods:  \n",
    "\n",
    "* Principal Component Analysis \n",
    "* Latent Semantic Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analysis\n",
    "\n",
    "In the first half of this workshop, we'll be using a very important supervised machine learning algorithm called the **support vector machine** to classify handwritten digits. This is a very well-studied problem in the machine learning community, and serves as a great starting point. First, let's import scikit-learn and a couple other modules we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, sklearn comes with a few preloaded datasets, so let's load up the handwritten digits dataset. This is a list of pixel intensities corresponding to images of handwritten digits plus their associated labels (0-9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Romeo and Juliet.', 'Juliet: O happy dagger!', 'Romeo died by dagger.', \"'Live free or die', that's the New-Hampshire's motto.\", 'Did you know, New-Hampshire is in New-England.']\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "\"Romeo and Juliet.\",\n",
    "\"Juliet: O happy dagger!\",\n",
    "\"Romeo died by dagger.\",\n",
    "\"'Live free or die', that's the New-Hampshire's motto.\",\n",
    "\"Did you know, New-Hampshire is in New-England.\"\n",
    "]\n",
    "print corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use matplotlib to see what one of these images looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'and', 'in', 'by', 'or', 'did', 'you', 'is', 'that']\n"
     ]
    }
   ],
   "source": [
    "preprocessed_corpus = [\n",
    "\"Romeo and Juliet\",\n",
    "\"Juliet O happy dagger\",\n",
    "\"Romeo die by dagger\",\n",
    "\"Live free or die that the NewHampshire motto\",\n",
    "\"Did you know NewHampshire is in NewEngland\"\n",
    "]\n",
    "\n",
    "key_words = ['die', 'dagger']\n",
    "\n",
    "stop_words = [\"the\", \"and\", \"in\", \"by\", \"or\", \"did\", \"you\", \"is\", \"that\"]\n",
    "\n",
    "print stop_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, matplotlib plots each value on a color scale. We can convert this to greyscale to get a better idea of the actual image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'and', u'by', u'dagger', u'did', u'die', u'free', u'happy', u'in', u'is', u'juliet', u'know', u'live', u'motto', u'newengland', u'newhampshire', u'or', u'romeo', u'that', u'the', u'you']\n"
     ]
    }
   ],
   "source": [
    "# vectorizer = CountVectorizer(min_df=0, stop_words=stop_words, strip_accents='ascii')\n",
    "vectorizer = CountVectorizer(min_df=0, stop_words=None, strip_accents='ascii')\n",
    "\n",
    "docs_tf = vectorizer.fit_transform(preprocessed_corpus)\n",
    "docs_query_tf = vectorizer.transform(preprocessed_corpus + [' '.join(key_words)])\n",
    "\n",
    "# analyze = vectorizer.build_analyzer()\n",
    "vocabulary_terms = vectorizer.get_feature_names()\n",
    "\n",
    "print vocabulary_terms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: die dagger\n",
      "\n",
      "--------------------- Rank list ----------------------\n",
      "0 0.434542044158 Romeo died by dagger.\n",
      "1 0.69154101474 Juliet: O happy dagger!\n",
      "2 0.837128775958 'Live free or die', that's the New-Hampshire's motto.\n",
      "3 1.0 Romeo and Juliet.\n",
      "4 1.0 Did you know, New-Hampshire is in New-England.\n"
     ]
    }
   ],
   "source": [
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "tfidf = transformer.fit_transform(docs_query_tf.toarray())\n",
    "tfidf_matrix = tfidf.toarray()[:-1] # D x V matrix\n",
    "query_tfidf = tfidf.toarray()[-1]\n",
    "\n",
    "print \n",
    "print 'Query:', ' '.join(key_words)\n",
    "print \n",
    "print '--------------------- Rank list ----------------------'\n",
    "query_doc_tfidf_cos_dist = [cosine(query_tfidf, doc_tfidf) for doc_tfidf in tfidf_matrix]\n",
    "query_doc_tfidf_sort_index = np.argsort(np.array(query_doc_tfidf_cos_dist))\n",
    "\n",
    "for rank, sort_index in enumerate(query_doc_tfidf_sort_index):\n",
    "    print rank, query_doc_tfidf_cos_dist[sort_index], corpus[sort_index]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf_matrix = docs_tf.toarray() # D x V matrix \n",
    "A = tf_matrix.T # V x D matrix \n",
    "\n",
    "U, s, V = np.linalg.svd(A, full_matrices=1, compute_uv=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U - the matrix of the eigenvectors of C = AA' (the term-term matrix). \n",
    "    it's a V x V matrix \n",
    "V - the matrix of the eigenvectors of B = A'A (the document-document matrix). \n",
    "    it's a D x D matrix \n",
    "s - the singular values, obtained as square roots of the eigenvalues of B.\n",
    "\n",
    "\n",
    "Video describing C: https://www.youtube.com/watch?v=joTa_FeMZ2s\n",
    "\n",
    "Video describing gamma: https://www.youtube.com/watch?v=m2a2K4lprQw\n",
    "\n",
    "That's pretty impressive. So what are those mysterious values gamma and C? The C parameter controls the penalty for misclassification of each example in the training data. Large values of C highly penalize misclassification, and thus will fit to the training data more exactly. However, this can lead to overfitting and trouble with outliers, in which case a smaller value of C should be chosen.\n",
    "\n",
    "The gamma parameter is somewhat more complicated, but it can be understood to be the radius of influence of the individual support vectors. More info can be found in the sklearn SVM documentation: http://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html\n",
    "\n",
    "So let's try changing the values of C and gamma and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: die dagger\n",
      "\n",
      "--------------------- Rank list ----------------------\n",
      "0 0.0479493579768 Romeo died by dagger.\n",
      "1 0.195476662549 Romeo and Juliet.\n",
      "2 0.195476662549 Juliet: O happy dagger!\n",
      "3 0.449474164103 'Live free or die', that's the New-Hampshire's motto.\n",
      "4 0.977968740393 Did you know, New-Hampshire is in New-England.\n"
     ]
    }
   ],
   "source": [
    "K = 3 # number of components\n",
    "\n",
    "A_reduced = np.dot(U[:,:K], np.dot(np.diag(s[:K]), V[:K, :]))\n",
    "\n",
    "# print A_reduced.shape\n",
    "\n",
    "\n",
    "terms_rep = np.dot(U[:,:K], np.diag(s[:K])) # V x K matrix \n",
    "\n",
    "key_word_indices = []\n",
    "for key_word in key_words:\n",
    "    key_word_indices.append(vocabulary_terms.index(key_word))\n",
    "\n",
    "docs_rep = np.dot(np.diag(s[:K]), V[:K, :]).T # D x K matrix \n",
    "\n",
    "             \n",
    "key_words_rep = terms_rep[key_word_indices,:]     \n",
    "\n",
    "# Now the query is represented by a vector computed as the centroid of the \n",
    "# vectors for its terms.\n",
    "# In our example, the query is die, dagger and so the vector is              \n",
    "                  \n",
    "\n",
    "query_rep = np.sum(key_words_rep, axis = 0)\n",
    "\n",
    "print query_rep\n",
    "\n",
    "\n",
    "\n",
    "print \n",
    "print 'Query:', ' '.join(key_words)\n",
    "print \n",
    "print '--------------------- Rank list ----------------------'\n",
    "query_doc_cos_dist = [cosine(query_rep, doc_rep) for doc_rep in docs_rep]\n",
    "query_doc_sort_index = np.argsort(np.array(query_doc_cos_dist))\n",
    "\n",
    "for rank, sort_index in enumerate(query_doc_sort_index):\n",
    "    print rank, query_doc_cos_dist[sort_index], corpus[sort_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
